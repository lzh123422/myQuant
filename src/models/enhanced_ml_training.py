#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆæœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒè„šæœ¬
ä½¿ç”¨æ›´å…ˆè¿›çš„ç®—æ³•å’Œç‰¹å¾å·¥ç¨‹
"""

import sys
import os
import qlib
from qlib.data import D
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class EnhancedMLTrainer:
    """å¢å¼ºç‰ˆæœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–è®­ç»ƒå™¨"""
        self.qlib_initialized = False
        self.models = {}
        self.results = {}
        self.feature_importance = {}
        
    def init_qlib(self):
        """åˆå§‹åŒ–Qlib"""
        try:
            print("ğŸ”§ åˆå§‹åŒ–Qlib...")
            qlib.init(provider_uri="~/.qlib/qlib_data/cn_data", region="cn")
            self.qlib_initialized = True
            print("âœ… Qlibåˆå§‹åŒ–æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ Qlibåˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def create_enhanced_features(self, symbols, start_time, end_time):
        """åˆ›å»ºå¢å¼ºç‰¹å¾"""
        print(f"ğŸ“Š åˆ›å»ºå¢å¼ºç‰¹å¾...")
        print(f"   è‚¡ç¥¨æ± : {symbols}")
        print(f"   æ—¶é—´èŒƒå›´: {start_time} åˆ° {end_time}")
        
        try:
            # ä¸€æ¬¡æ€§è·å–æ‰€æœ‰è‚¡ç¥¨çš„åŸºç¡€æ•°æ®
            fields = ["$close", "$open", "$high", "$low", "$volume", "$factor"]
            data = D.features(symbols, fields, start_time=start_time, end_time=end_time)
            
            if data.empty:
                print("âŒ è·å–çš„æ•°æ®ä¸ºç©º")
                return None, None
            
            print(f"   âœ… æ•°æ®è·å–æˆåŠŸï¼Œæ•°æ®å½¢çŠ¶: {data.shape}")
            
            all_features = []
            all_labels = []
            
            for symbol in symbols:
                try:
                    print(f"   å¤„ç†è‚¡ç¥¨: {symbol}")
                    
                    # è·å–å•ä¸ªè‚¡ç¥¨çš„æ•°æ®
                    symbol_data = data.loc[symbol]
                    
                    if symbol_data.empty:
                        print(f"   âš ï¸  {symbol} æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡")
                        continue
                    
                    # åˆ›å»ºç‰¹å¾DataFrame
                    df = pd.DataFrame(index=symbol_data.index)
                    df['close'] = symbol_data['$close']
                    df['open'] = symbol_data['$open']
                    df['high'] = symbol_data['$high']
                    df['low'] = symbol_data['$low']
                    df['volume'] = symbol_data['$volume']
                    df['factor'] = symbol_data['$factor']
                    df['symbol'] = symbol
                    
                    # åŸºç¡€ä»·æ ¼ç‰¹å¾
                    df['price_change'] = df['close'].pct_change()
                    df['price_change_2d'] = df['close'].pct_change(2)
                    df['price_change_5d'] = df['close'].pct_change(5)
                    df['price_change_10d'] = df['close'].pct_change(10)
                    
                    # ç§»åŠ¨å¹³å‡çº¿
                    df['ma_5'] = df['close'].rolling(5).mean()
                    df['ma_10'] = df['close'].rolling(10).mean()
                    df['ma_20'] = df['close'].rolling(20).mean()
                    df['ma_60'] = df['close'].rolling(60).mean()
                    
                    # ä»·æ ¼ä½ç½®æŒ‡æ ‡
                    df['price_position'] = (df['close'] - df['low']) / (df['high'] - df['low'])
                    df['price_ma5_ratio'] = df['close'] / df['ma_5']
                    df['price_ma20_ratio'] = df['close'] / df['ma_20']
                    df['price_ma60_ratio'] = df['close'] / df['ma_60']
                    
                    # æˆäº¤é‡ç‰¹å¾
                    df['volume_ma5'] = df['volume'].rolling(5).mean()
                    df['volume_ma20'] = df['volume'].rolling(20).mean()
                    df['volume_ratio'] = df['volume'] / df['volume_ma20']
                    df['volume_change'] = df['volume'].pct_change()
                    
                    # æ³¢åŠ¨ç‡ç‰¹å¾
                    df['volatility_5d'] = df['price_change'].rolling(5).std()
                    df['volatility_10d'] = df['price_change'].rolling(10).std()
                    df['volatility_20d'] = df['price_change'].rolling(20).std()
                    
                    # æŠ€æœ¯æŒ‡æ ‡
                    df['rsi_14'] = self._calculate_rsi(df['close'], 14)
                    df['macd'], df['macd_signal'] = self._calculate_macd(df['close'])
                    df['bollinger_upper'], df['bollinger_lower'] = self._calculate_bollinger_bands(df['close'])
                    
                    # è¶‹åŠ¿ç‰¹å¾
                    df['trend_5d'] = np.where(df['ma_5'] > df['ma_20'], 1, -1)
                    df['trend_20d'] = np.where(df['ma_20'] > df['ma_60'], 1, -1)
                    df['momentum'] = df['close'] / df['close'].shift(20) - 1
                    
                    # ä»·æ ¼åŒºé—´ç‰¹å¾
                    df['price_range'] = (df['high'] - df['low']) / df['close']
                    df['price_range_5d'] = df['price_range'].rolling(5).mean()
                    
                    # æˆäº¤é‡ä»·æ ¼å…³ç³»
                    df['volume_price_trend'] = df['volume'] * df['price_change']
                    df['volume_price_trend_5d'] = df['volume_price_trend'].rolling(5).sum()
                    
                    # åˆ é™¤åŒ…å«NaNçš„è¡Œ
                    df = df.dropna()
                    
                    if len(df) < 50:  # è‡³å°‘éœ€è¦50ä¸ªæ•°æ®ç‚¹
                        print(f"   âš ï¸  {symbol} æœ‰æ•ˆæ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
                        continue
                    
                    # åˆ›å»ºæ ‡ç­¾ï¼ˆæœªæ¥5å¤©æ¶¨è·Œï¼‰
                    df['future_return'] = df['close'].shift(-5) / df['close'] - 1
                    df['label'] = np.where(df['future_return'] > 0.02, 1, 0)  # 2%é˜ˆå€¼
                    
                    # é€‰æ‹©ç‰¹å¾åˆ—
                    feature_columns = [
                        'close', 'open', 'high', 'low', 'volume', 'factor',
                        'price_change', 'price_change_2d', 'price_change_5d', 'price_change_10d',
                        'ma_5', 'ma_10', 'ma_20', 'ma_60',
                        'price_position', 'price_ma5_ratio', 'price_ma20_ratio', 'price_ma60_ratio',
                        'volume_ma5', 'volume_ma20', 'volume_ratio', 'volume_change',
                        'volatility_5d', 'volatility_10d', 'volatility_20d',
                        'rsi_14', 'macd', 'macd_signal',
                        'bollinger_upper', 'bollinger_lower',
                        'trend_5d', 'trend_20d', 'momentum',
                        'price_range', 'price_range_5d',
                        'volume_price_trend', 'volume_price_trend_5d'
                    ]
                    
                    # ç¡®ä¿æ‰€æœ‰ç‰¹å¾åˆ—éƒ½å­˜åœ¨
                    available_features = [col for col in feature_columns if col in df.columns]
                    features = df[available_features].copy()
                    labels = df['label'].copy()
                    
                    # åˆ é™¤åŒ…å«NaNçš„è¡Œ
                    valid_mask = ~(features.isna().any(axis=1) | labels.isna())
                    features = features[valid_mask]
                    labels = labels[valid_mask]
                    
                    if len(features) > 0:
                        all_features.append(features)
                        all_labels.append(labels)
                        print(f"   âœ… {symbol} ç‰¹å¾åˆ›å»ºæˆåŠŸï¼Œæ ·æœ¬æ•°: {len(features)}")
                    
                except Exception as e:
                    print(f"   âŒ å¤„ç† {symbol} æ—¶å‡ºé”™: {e}")
                    continue
            
            if not all_features:
                print("âŒ æ²¡æœ‰æˆåŠŸåˆ›å»ºä»»ä½•ç‰¹å¾")
                return None, None
            
            # åˆå¹¶æ‰€æœ‰è‚¡ç¥¨çš„ç‰¹å¾
            combined_features = pd.concat(all_features, ignore_index=True)
            combined_labels = pd.concat(all_labels, ignore_index=True)
            
            print(f"âœ… ç‰¹å¾åˆ›å»ºå®Œæˆ")
            print(f"   æ€»æ ·æœ¬æ•°: {len(combined_features)}")
            print(f"   ç‰¹å¾æ•°é‡: {len(combined_features.columns)}")
            print(f"   æ ‡ç­¾åˆ†å¸ƒ: {combined_labels.value_counts().to_dict()}")
            
            return combined_features, combined_labels
            
        except Exception as e:
            print(f"âŒ ç‰¹å¾åˆ›å»ºè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return None, None
    
    def _calculate_rsi(self, prices, period=14):
        """è®¡ç®—RSIæŒ‡æ ‡"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi
    
    def _calculate_macd(self, prices, fast=12, slow=26, signal=9):
        """è®¡ç®—MACDæŒ‡æ ‡"""
        ema_fast = prices.ewm(span=fast).mean()
        ema_slow = prices.ewm(span=slow).mean()
        macd = ema_fast - ema_slow
        macd_signal = macd.ewm(span=signal).mean()
        return macd, macd_signal
    
    def _calculate_bollinger_bands(self, prices, period=20, std_dev=2):
        """è®¡ç®—å¸ƒæ—å¸¦"""
        ma = prices.rolling(period).mean()
        std = prices.rolling(period).std()
        upper = ma + (std * std_dev)
        lower = ma - (std * std_dev)
        return upper, lower
    
    def train_enhanced_models(self, features_df, labels):
        """è®­ç»ƒå¤šä¸ªå¢å¼ºæ¨¡å‹"""
        print("\nğŸ¤– å¼€å§‹è®­ç»ƒå¢å¼ºæ¨¡å‹...")
        
        from sklearn.model_selection import train_test_split
        from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
        from sklearn.linear_model import LogisticRegression
        from sklearn.svm import SVC
        from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
        from sklearn.preprocessing import StandardScaler
        
        # æ•°æ®é¢„å¤„ç†
        X = features_df.fillna(0)  # å¡«å……ç¼ºå¤±å€¼
        y = labels
        
        # åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42, stratify=y
        )
        
        # æ ‡å‡†åŒ–ç‰¹å¾
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # å®šä¹‰æ¨¡å‹
        models = {
            'RandomForest_Enhanced': RandomForestClassifier(
                n_estimators=200, max_depth=15, random_state=42, n_jobs=-1
            ),
            'GradientBoosting': GradientBoostingClassifier(
                n_estimators=200, max_depth=8, random_state=42, learning_rate=0.1
            ),
            'LogisticRegression': LogisticRegression(
                random_state=42, max_iter=1000, C=1.0
            ),
            'SVM': SVC(
                random_state=42, probability=True, kernel='rbf'
            )
        }
        
        # è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹
        for name, model in models.items():
            print(f"\nğŸ“Š è®­ç»ƒæ¨¡å‹: {name}")
            
            try:
                if name in ['LogisticRegression', 'SVM']:
                    # çº¿æ€§æ¨¡å‹ä½¿ç”¨æ ‡å‡†åŒ–æ•°æ®
                    model.fit(X_train_scaled, y_train)
                    y_pred = model.predict(X_test_scaled)
                    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, 'predict_proba') else None
                else:
                    # æ ‘æ¨¡å‹ä½¿ç”¨åŸå§‹æ•°æ®
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)
                    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None
                
                # è®¡ç®—å‡†ç¡®ç‡
                accuracy = accuracy_score(y_test, y_pred)
                
                # ä¿å­˜ç»“æœ
                self.models[name] = model
                self.results[name] = {
                    'accuracy': accuracy,
                    'y_pred': y_pred,
                    'y_pred_proba': y_pred_proba,
                    'y_test': y_test,
                    'feature_names': X.columns.tolist()
                }
                
                # è·å–ç‰¹å¾é‡è¦æ€§ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if hasattr(model, 'feature_importances_'):
                    self.feature_importance[name] = dict(zip(X.columns, model.feature_importances_))
                
                print(f"   âœ… è®­ç»ƒå®Œæˆï¼Œå‡†ç¡®ç‡: {accuracy:.4f}")
                
                # è¯¦ç»†åˆ†ç±»æŠ¥å‘Š
                print(f"   åˆ†ç±»æŠ¥å‘Š:")
                print(classification_report(y_test, y_pred))
                
            except Exception as e:
                print(f"   âŒ è®­ç»ƒå¤±è´¥: {e}")
                continue
        
        print(f"\nâœ… æ‰€æœ‰æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
        return True
    
    def plot_model_comparison(self):
        """ç»˜åˆ¶æ¨¡å‹æ€§èƒ½å¯¹æ¯”"""
        if not self.results:
            print("âŒ æ²¡æœ‰è®­ç»ƒç»“æœå¯ä¾›ç»˜åˆ¶")
            return
        
        print("\nğŸ¨ ç»˜åˆ¶æ¨¡å‹æ€§èƒ½å¯¹æ¯”...")
        
        # å‡†å¤‡æ•°æ®
        model_names = list(self.results.keys())
        accuracies = [self.results[name]['accuracy'] for name in model_names]
        
        # åˆ›å»ºå­å›¾
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=['æ¨¡å‹å‡†ç¡®ç‡å¯¹æ¯”', 'ç‰¹å¾é‡è¦æ€§å¯¹æ¯”', 'é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ', 'æ··æ·†çŸ©é˜µ'],
            specs=[[{"type": "bar"}, {"type": "bar"}],
                   [{"type": "histogram"}, {"type": "heatmap"}]]
        )
        
        # 1. å‡†ç¡®ç‡å¯¹æ¯”
        fig.add_trace(
            go.Bar(x=model_names, y=accuracies, name='å‡†ç¡®ç‡', 
                   marker_color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']),
            row=1, col=1
        )
        
        # 2. ç‰¹å¾é‡è¦æ€§å¯¹æ¯”ï¼ˆé€‰æ‹©ç¬¬ä¸€ä¸ªæœ‰ç‰¹å¾é‡è¦æ€§çš„æ¨¡å‹ï¼‰
        if self.feature_importance:
            first_model = list(self.feature_importance.keys())[0]
            importance_data = self.feature_importance[first_model]
            top_features = sorted(importance_data.items(), key=lambda x: x[1], reverse=True)[:15]
            
            feature_names = [item[0] for item in top_features]
            importance_values = [item[1] for item in top_features]
            
            fig.add_trace(
                go.Bar(x=importance_values, y=feature_names, orientation='h', 
                       name='ç‰¹å¾é‡è¦æ€§', marker_color='#2ca02c'),
                row=1, col=2
            )
        
        # 3. é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ
        for name in model_names:
            if self.results[name]['y_pred_proba'] is not None:
                fig.add_trace(
                    go.Histogram(x=self.results[name]['y_pred_proba'], name=f'{name}_æ¦‚ç‡',
                               opacity=0.7, nbinsx=20),
                    row=2, col=1
                )
        
        # 4. æ··æ·†çŸ©é˜µï¼ˆé€‰æ‹©ç¬¬ä¸€ä¸ªæ¨¡å‹ï¼‰
        first_model = model_names[0]
        y_test = self.results[first_model]['y_test']
        y_pred = self.results[first_model]['y_pred']
        
        from sklearn.metrics import confusion_matrix
        cm = confusion_matrix(y_test, y_pred)
        
        fig.add_trace(
            go.Heatmap(z=cm, x=['é¢„æµ‹ä¸‹è·Œ', 'é¢„æµ‹ä¸Šæ¶¨'], y=['å®é™…ä¸‹è·Œ', 'å®é™…ä¸Šæ¶¨'],
                       colorscale='Blues', name='æ··æ·†çŸ©é˜µ'),
            row=2, col=2
        )
        
        # æ›´æ–°å¸ƒå±€
        fig.update_layout(
            title='å¢å¼ºæ¨¡å‹æ€§èƒ½å¯¹æ¯”åˆ†æ',
            height=800,
            showlegend=True
        )
        
        # ä¿å­˜å›¾è¡¨
        output_file = 'results/enhanced_models_comparison.html'
        fig.write_html(output_file)
        print(f"âœ… æ¨¡å‹å¯¹æ¯”å›¾è¡¨å·²ä¿å­˜: {output_file}")
        
        return fig
    
    def save_enhanced_report(self, filename=None):
        """ä¿å­˜å¢å¼ºæ¨¡å‹æŠ¥å‘Š"""
        if not self.results:
            print("âŒ æ²¡æœ‰è®­ç»ƒç»“æœå¯ä¾›ä¿å­˜")
            return
        
        if filename is None:
            filename = 'results/enhanced_models_report.txt'
        
        print(f"\nğŸ“ ä¿å­˜å¢å¼ºæ¨¡å‹æŠ¥å‘Š: {filename}")
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("å¢å¼ºç‰ˆæœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒæŠ¥å‘Š\n")
            f.write("=" * 50 + "\n\n")
            
            # æ¨¡å‹æ€§èƒ½å¯¹æ¯”
            f.write("ğŸ“Š æ¨¡å‹æ€§èƒ½å¯¹æ¯”:\n")
            f.write("-" * 30 + "\n")
            for name, result in self.results.items():
                f.write(f"æ¨¡å‹: {name}\n")
                f.write(f"å‡†ç¡®ç‡: {result['accuracy']:.4f}\n")
                f.write("-" * 20 + "\n")
            
            # æœ€ä½³æ¨¡å‹
            best_model = max(self.results.keys(), key=lambda x: self.results[x]['accuracy'])
            f.write(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model}\n")
            f.write(f"æœ€ä½³å‡†ç¡®ç‡: {self.results[best_model]['accuracy']:.4f}\n\n")
            
            # ç‰¹å¾é‡è¦æ€§
            if self.feature_importance:
                f.write("ğŸ¯ ç‰¹å¾é‡è¦æ€§åˆ†æ:\n")
                f.write("-" * 30 + "\n")
                for model_name, importance in self.feature_importance.items():
                    f.write(f"\n{model_name} ç‰¹å¾é‡è¦æ€§ (å‰15):\n")
                    sorted_importance = sorted(importance.items(), key=lambda x: x[1], reverse=True)[:15]
                    for feature, imp in sorted_importance:
                        f.write(f"   {feature}: {imp:.4f}\n")
            
            # è®­ç»ƒä¿¡æ¯
            f.write(f"\nğŸ“… è®­ç»ƒä¿¡æ¯:\n")
            f.write("-" * 30 + "\n")
            f.write(f"æ¨¡å‹æ•°é‡: {len(self.models)}\n")
            f.write(f"ç‰¹å¾æ•°é‡: {len(self.results[list(self.results.keys())[0]]['feature_names'])}\n")
            f.write(f"ç®—æ³•ç±»å‹: é›†æˆå­¦ä¹  + çº¿æ€§æ¨¡å‹ + SVM\n")
            f.write(f"ç‰¹å¾å·¥ç¨‹: æŠ€æœ¯æŒ‡æ ‡ + ç»Ÿè®¡ç‰¹å¾ + è¶‹åŠ¿ç‰¹å¾\n")
        
        print(f"âœ… å¢å¼ºæ¨¡å‹æŠ¥å‘Šå·²ä¿å­˜: {filename}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¢å¼ºç‰ˆæœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒ")
    print("=" * 50)
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = EnhancedMLTrainer()
    
    # åˆå§‹åŒ–Qlib
    if not trainer.init_qlib():
        return
    
    # è‚¡ç¥¨æ± å’Œæ—¶é—´èŒƒå›´
    symbols = [
        "SH600000", "SH600004", "SH600009", "SH600010", "SH600011",
        "SH600016", "SH600019", "SH600025", "SH600027", "SH600028"
    ]
    start_time = "2019-01-01"
    end_time = "2020-09-25"
    
    # åˆ›å»ºå¢å¼ºç‰¹å¾
    features, labels = trainer.create_enhanced_features(symbols, start_time, end_time)
    
    if features is None:
        print("âŒ ç‰¹å¾åˆ›å»ºå¤±è´¥")
        return
    
    # è®­ç»ƒå¢å¼ºæ¨¡å‹
    if not trainer.train_enhanced_models(features, labels):
        print("âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥")
        return
    
    # ç»˜åˆ¶æ¨¡å‹å¯¹æ¯”
    trainer.plot_model_comparison()
    
    # ä¿å­˜æŠ¥å‘Š
    trainer.save_enhanced_report()
    
    print("\nğŸ‰ å¢å¼ºæ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    print("ğŸ’¡ æŸ¥çœ‹ç»“æœ:")
    print("1. æ¨¡å‹å¯¹æ¯”å›¾è¡¨: results/enhanced_models_comparison.html")
    print("2. è®­ç»ƒæŠ¥å‘Š: results/enhanced_models_report.txt")

if __name__ == "__main__":
    main() 